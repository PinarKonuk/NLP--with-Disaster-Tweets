{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This notebook uses Natural Language Processing (NLP) techniques to classify tweets as either real disasters or not.","metadata":{"execution":{"iopub.status.busy":"2025-08-06T14:32:47.132601Z","iopub.execute_input":"2025-08-06T14:32:47.132955Z","iopub.status.idle":"2025-08-06T14:32:47.140154Z","shell.execute_reply.started":"2025-08-06T14:32:47.132926Z","shell.execute_reply":"2025-08-06T14:32:47.139025Z"}}},{"cell_type":"markdown","source":"# 1. Setup and Data Loading\nThis section imports necessary libraries and loads the dataset.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T10:59:24.076794Z","iopub.execute_input":"2025-08-05T10:59:24.077686Z","iopub.status.idle":"2025-08-05T10:59:24.084505Z","shell.execute_reply.started":"2025-08-05T10:59:24.077656Z","shell.execute_reply":"2025-08-05T10:59:24.083265Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"The output shows the data files available in the input directory.\n\n- /kaggle/input/nlp-getting-started/sample_submission.csv\n\n- /kaggle/input/nlp-getting-started/train.csv\n\n- /kaggle/input/nlp-getting-started/test.csv","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix,accuracy_score\nimport re\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport string","metadata":{"execution":{"iopub.status.busy":"2025-08-05T11:03:52.668800Z","iopub.execute_input":"2025-08-05T11:03:52.669160Z","iopub.status.idle":"2025-08-05T11:03:52.674573Z","shell.execute_reply.started":"2025-08-05T11:03:52.669137Z","shell.execute_reply":"2025-08-05T11:03:52.673615Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The datasets are loaded into pandas DataFrames.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsample = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:03:55.530491Z","iopub.execute_input":"2025-08-05T11:03:55.531594Z","iopub.status.idle":"2025-08-05T11:03:55.578897Z","shell.execute_reply.started":"2025-08-05T11:03:55.531562Z","shell.execute_reply":"2025-08-05T11:03:55.578012Z"}},"outputs":[],"execution_count":141},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis (EDA)\nThis part of the notebook explores the training data to understand its structure and characteristics.\n\nDisplay the first 5 rows of the training data.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:03:57.307256Z","iopub.execute_input":"2025-08-05T11:03:57.308035Z","iopub.status.idle":"2025-08-05T11:03:57.316700Z","shell.execute_reply.started":"2025-08-05T11:03:57.308002Z","shell.execute_reply":"2025-08-05T11:03:57.315925Z"}},"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":142},{"cell_type":"markdown","source":"\n**The output shows columns: id, keyword, location, text, and target. The target column indicates whether the tweet is about a real disaster (1) or not (0).**\n","metadata":{}},{"cell_type":"code","source":"# Check the shape of the training data\ntrain.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:00.253476Z","iopub.execute_input":"2025-08-05T11:04:00.253774Z","iopub.status.idle":"2025-08-05T11:04:00.259572Z","shell.execute_reply.started":"2025-08-05T11:04:00.253752Z","shell.execute_reply":"2025-08-05T11:04:00.258547Z"}},"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"(7613, 5)"},"metadata":{}}],"execution_count":143},{"cell_type":"code","source":"# Check the columns of the training data.\ntrain.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:01.944941Z","iopub.execute_input":"2025-08-05T11:04:01.945244Z","iopub.status.idle":"2025-08-05T11:04:01.951677Z","shell.execute_reply.started":"2025-08-05T11:04:01.945223Z","shell.execute_reply":"2025-08-05T11:04:01.950672Z"}},"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"},"metadata":{}}],"execution_count":144},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Get information about the DataFrame, including data types and non-null values.\ntrain.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:04.983096Z","iopub.execute_input":"2025-08-05T11:04:04.983385Z","iopub.status.idle":"2025-08-05T11:04:04.995942Z","shell.execute_reply.started":"2025-08-05T11:04:04.983365Z","shell.execute_reply":"2025-08-05T11:04:04.994740Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        7613 non-null   int64 \n 1   keyword   7552 non-null   object\n 2   location  5080 non-null   object\n 3   text      7613 non-null   object\n 4   target    7613 non-null   int64 \ndtypes: int64(2), object(3)\nmemory usage: 297.5+ KB\n","output_type":"stream"}],"execution_count":145},{"cell_type":"code","source":"# Count the number of tweets for each target class.\ntrain['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:08.303781Z","iopub.execute_input":"2025-08-05T11:04:08.304114Z","iopub.status.idle":"2025-08-05T11:04:08.310869Z","shell.execute_reply.started":"2025-08-05T11:04:08.304084Z","shell.execute_reply":"2025-08-05T11:04:08.309913Z"}},"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}],"execution_count":146},{"cell_type":"code","source":"# Check for missing values in each column.\ntrain.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:10.497219Z","iopub.execute_input":"2025-08-05T11:04:10.497523Z","iopub.status.idle":"2025-08-05T11:04:10.506209Z","shell.execute_reply.started":"2025-08-05T11:04:10.497500Z","shell.execute_reply":"2025-08-05T11:04:10.505398Z"}},"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"id             0\nkeyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64"},"metadata":{}}],"execution_count":147},{"cell_type":"code","source":"train['text_length'] = train['text'].apply(len)\ntrain['text_length'].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:13.257339Z","iopub.execute_input":"2025-08-05T11:04:13.257639Z","iopub.status.idle":"2025-08-05T11:04:13.271349Z","shell.execute_reply.started":"2025-08-05T11:04:13.257618Z","shell.execute_reply":"2025-08-05T11:04:13.270296Z"}},"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"count    7613.000000\nmean      101.037436\nstd        33.781325\nmin         7.000000\n25%        78.000000\n50%       107.000000\n75%       133.000000\nmax       157.000000\nName: text_length, dtype: float64"},"metadata":{}}],"execution_count":148},{"cell_type":"code","source":"sample_text = train['text'][0]\nsample_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:15.935534Z","iopub.execute_input":"2025-08-05T11:04:15.935940Z","iopub.status.idle":"2025-08-05T11:04:15.941752Z","shell.execute_reply.started":"2025-08-05T11:04:15.935912Z","shell.execute_reply":"2025-08-05T11:04:15.941125Z"}},"outputs":[{"execution_count":149,"output_type":"execute_result","data":{"text/plain":"'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"},"metadata":{}}],"execution_count":149},{"cell_type":"markdown","source":"# 3. Text Preprocessing\nA function clean_text is defined to preprocess the tweet text. This involves converting the text to lowercase, removing numbers and punctuation, and removing English stopwords.","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:18.469693Z","iopub.execute_input":"2025-08-05T11:04:18.470023Z","iopub.status.idle":"2025-08-05T11:04:18.475794Z","shell.execute_reply.started":"2025-08-05T11:04:18.469990Z","shell.execute_reply":"2025-08-05T11:04:18.475019Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":150},{"cell_type":"code","source":"def clean_text(text):\n    # 1. Convert to lowercase\n    text = text.lower()\n\n    # 2. Remove numbers and punctuation\n    text = re.sub(r'\\d+', '', text)  \n    text = text.translate(str.maketrans('', '', string.punctuation))  # noktalama\n\n    # 3. Tokenize\n    tokens = text.split()\n\n    # 4.  Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word not in stop_words]\n\n    # 5. Join tokens back into a string\n    cleaned_text = ' '.join(tokens)\n    return cleaned_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:19.885151Z","iopub.execute_input":"2025-08-05T11:04:19.885794Z","iopub.status.idle":"2025-08-05T11:04:19.890901Z","shell.execute_reply.started":"2025-08-05T11:04:19.885765Z","shell.execute_reply":"2025-08-05T11:04:19.890005Z"}},"outputs":[],"execution_count":151},{"cell_type":"code","source":"train['clean_text'] = train['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:22.595087Z","iopub.execute_input":"2025-08-05T11:04:22.595368Z","iopub.status.idle":"2025-08-05T11:04:23.482392Z","shell.execute_reply.started":"2025-08-05T11:04:22.595347Z","shell.execute_reply":"2025-08-05T11:04:23.481606Z"}},"outputs":[],"execution_count":152},{"cell_type":"markdown","source":"# 4. Model Training and Evaluation\nThe preprocessed data is split into training and testing sets, and a Logistic Regression model is trained and evaluated.","metadata":{}},{"cell_type":"code","source":"# Split data\nX = train['clean_text']\ny = train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:25.725693Z","iopub.execute_input":"2025-08-05T11:04:25.726277Z","iopub.status.idle":"2025-08-05T11:04:25.734908Z","shell.execute_reply.started":"2025-08-05T11:04:25.726249Z","shell.execute_reply":"2025-08-05T11:04:25.734000Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"# Use TfidfVectorizer to convert the text data into a matrix of TF-IDF features.\nvectorizer = TfidfVectorizer(\n    max_features=5000,\n    ngram_range=(1,2),\n    max_df=0.95,\n    min_df=5,\n    sublinear_tf=True\n\n)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:27.299672Z","iopub.execute_input":"2025-08-05T11:04:27.300007Z","iopub.status.idle":"2025-08-05T11:04:27.611412Z","shell.execute_reply.started":"2025-08-05T11:04:27.299981Z","shell.execute_reply":"2025-08-05T11:04:27.610693Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"# Train a Logistic Regression model. class_weight='balanced' is used to handle the slight class imbalance.\nmodel = LogisticRegression(class_weight='balanced')\nmodel.fit(X_train_vec, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:30.846433Z","iopub.execute_input":"2025-08-05T11:04:30.846738Z","iopub.status.idle":"2025-08-05T11:04:30.911943Z","shell.execute_reply.started":"2025-08-05T11:04:30.846713Z","shell.execute_reply":"2025-08-05T11:04:30.911135Z"}},"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(class_weight='balanced')","text/html":"<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":155},{"cell_type":"code","source":"y_pred = model.predict(X_test_vec)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:04:32.823135Z","iopub.execute_input":"2025-08-05T11:04:32.824187Z","iopub.status.idle":"2025-08-05T11:04:32.841495Z","shell.execute_reply.started":"2025-08-05T11:04:32.824148Z","shell.execute_reply":"2025-08-05T11:04:32.840619Z"}},"outputs":[{"name":"stdout","text":"[[718 156]\n [158 491]]\n              precision    recall  f1-score   support\n\n           0       0.82      0.82      0.82       874\n           1       0.76      0.76      0.76       649\n\n    accuracy                           0.79      1523\n   macro avg       0.79      0.79      0.79      1523\nweighted avg       0.79      0.79      0.79      1523\n\n","output_type":"stream"}],"execution_count":156},{"cell_type":"code","source":"y_prob = model.predict_proba(X_test_vec)[:, 1]\naccuracy = accuracy_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_prob)\n\nprint(\"Accuracy       : %\", round(accuracy * 100, 2))\nprint(\"ROC AUC Score  :\", round(roc_auc, 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:03:24.528716Z","iopub.execute_input":"2025-08-05T11:03:24.529611Z","iopub.status.idle":"2025-08-05T11:03:24.540075Z","shell.execute_reply.started":"2025-08-05T11:03:24.529547Z","shell.execute_reply":"2025-08-05T11:03:24.538866Z"}},"outputs":[{"name":"stdout","text":"Accuracy       : % 79.38\nROC AUC Score  : 0.8551\n","output_type":"stream"}],"execution_count":139},{"cell_type":"markdown","source":"# 5. Making Predictions on the Test Set\nThe same preprocessing steps and trained model are used to make predictions on the provided test.csv file.","metadata":{}},{"cell_type":"code","source":"test['clean_text'] = test['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:10:30.300412Z","iopub.execute_input":"2025-08-05T11:10:30.301235Z","iopub.status.idle":"2025-08-05T11:10:30.687448Z","shell.execute_reply.started":"2025-08-05T11:10:30.301204Z","shell.execute_reply":"2025-08-05T11:10:30.686405Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"test_final = vectorizer.transform(test['clean_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:11:09.849633Z","iopub.execute_input":"2025-08-05T11:11:09.849982Z","iopub.status.idle":"2025-08-05T11:11:09.916402Z","shell.execute_reply.started":"2025-08-05T11:11:09.849957Z","shell.execute_reply":"2025-08-05T11:11:09.915351Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"y_pred_test = model.predict(test_final)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:11:36.732083Z","iopub.execute_input":"2025-08-05T11:11:36.732362Z","iopub.status.idle":"2025-08-05T11:11:36.737418Z","shell.execute_reply.started":"2025-08-05T11:11:36.732342Z","shell.execute_reply":"2025-08-05T11:11:36.736273Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"\nsample[\"target\"] = y_pred_test\nsample.to_csv(\"sample_submission.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:13:36.485170Z","iopub.execute_input":"2025-08-05T11:13:36.486058Z","iopub.status.idle":"2025-08-05T11:13:36.494167Z","shell.execute_reply.started":"2025-08-05T11:13:36.486030Z","shell.execute_reply":"2025-08-05T11:13:36.493290Z"}},"outputs":[],"execution_count":164},{"cell_type":"code","source":"import joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:29:24.254745Z","iopub.execute_input":"2025-08-05T11:29:24.255592Z","iopub.status.idle":"2025-08-05T11:29:24.259556Z","shell.execute_reply.started":"2025-08-05T11:29:24.255562Z","shell.execute_reply":"2025-08-05T11:29:24.258341Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"joblib.dump(model, \"model.pkl\")\njoblib.dump(vectorizer, \"vectorizer.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T11:29:40.679520Z","iopub.execute_input":"2025-08-05T11:29:40.679806Z","iopub.status.idle":"2025-08-05T11:29:40.890077Z","shell.execute_reply.started":"2025-08-05T11:29:40.679784Z","shell.execute_reply":"2025-08-05T11:29:40.889235Z"}},"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"['vectorizer.pkl']"},"metadata":{}}],"execution_count":166}]}